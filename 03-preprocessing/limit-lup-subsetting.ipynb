{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.abspath('')\n",
    "\n",
    "# Search for the 'constants.py' file starting from the current directory and moving up the hierarchy\n",
    "project_root = current_dir\n",
    "while not os.path.isfile(os.path.join(project_root, 'constants.py')):\n",
    "    project_root = os.path.dirname(project_root)\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import LIMIT, DATA_PATH, LIMIT_SUBSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bsf31\\\\Documents\\\\post-meds\\\\data\\\\policy-data\\\\preprocessing\\\\ready-dataset.gpkg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIMIT_SUBSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the shapefile using geopandas\\nlimit = gpd.read_file(LIMIT)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load the shapefile using geopandas\n",
    "limit = gpd.read_file(LIMIT)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"limit['anho_capa'] = limit['anho_capa'].astype(int)\\n\\nlimit = limit[['id', 'put_id', 'anho_capa','fecha_res', 'geometry' ]]\\n\\nfiltered_limit = limit[limit['anho_capa'] >= 2000]\\nfiltered_limit['area'] = filtered_limit['geometry'].area\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''limit['anho_capa'] = limit['anho_capa'].astype(int)\n",
    "\n",
    "limit = limit[['id', 'put_id', 'anho_capa','fecha_res', 'geometry' ]]\n",
    "\n",
    "filtered_limit = limit[limit['anho_capa'] >= 2000]\n",
    "filtered_limit['area'] = filtered_limit['geometry'].area'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Sort properties by registration year\\nproperties = filtered_limit.sort_values(by='anho_capa')\\n\\n# Convert fecha_res to datetime format\\nproperties['fecha_res'] = pd.to_datetime(properties['fecha_res'], errors='coerce')\\n\\n# For rows with NaT (Not a Timestamp) in fecha_res, assign a default date based on their year\\nproperties.loc[properties['fecha_res'].isna(), 'fecha_res'] = pd.to_datetime(properties['anho_capa'].astype(str) + '-01-01')\\n\\n# Sort properties by fecha_res\\nproperties = properties.sort_values(by='fecha_res')\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Sort properties by registration year\n",
    "properties = filtered_limit.sort_values(by='anho_capa')\n",
    "\n",
    "# Convert fecha_res to datetime format\n",
    "properties['fecha_res'] = pd.to_datetime(properties['fecha_res'], errors='coerce')\n",
    "\n",
    "# For rows with NaT (Not a Timestamp) in fecha_res, assign a default date based on their year\n",
    "properties.loc[properties['fecha_res'].isna(), 'fecha_res'] = pd.to_datetime(properties['anho_capa'].astype(str) + '-01-01')\n",
    "\n",
    "# Sort properties by fecha_res\n",
    "properties = properties.sort_values(by='fecha_res')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Create an empty GeoDataFrame to store the final processed properties\\nfinal_properties = gpd.GeoDataFrame(columns=properties.columns)\\n\\n# Add properties from the year 2000 to final_properties as the baseline\\nfinal_properties = pd.concat([final_properties, properties[properties[\\'anho_capa\\'] == 2000]])\\n\\nfor year in range(2001, 2023):  # Loop from 2001 to 2022\\n    # Get properties of the current year\\n    current_year_properties = properties[properties[\\'anho_capa\\'] == year]\\n    \\n    # Iterate over each property of the current year\\n    for idx, current_property in current_year_properties.iterrows():\\n        # Subtract geometries of older properties from the current property\\n        for _, older_property in final_properties.iterrows():\\n            current_property[\\'geometry\\'] = current_property[\\'geometry\\'].difference(older_property[\\'geometry\\'])\\n        \\n        # Append the \"cut\" current property to the final_properties GeoDataFrame\\n        final_properties = pd.concat([final_properties, current_property.to_frame().T])\\nfinal_properties.crs = properties.crs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Create an empty GeoDataFrame to store the final processed properties\n",
    "final_properties = gpd.GeoDataFrame(columns=properties.columns)\n",
    "\n",
    "# Add properties from the year 2000 to final_properties as the baseline\n",
    "final_properties = pd.concat([final_properties, properties[properties['anho_capa'] == 2000]])\n",
    "\n",
    "for year in range(2001, 2023):  # Loop from 2001 to 2022\n",
    "    # Get properties of the current year\n",
    "    current_year_properties = properties[properties['anho_capa'] == year]\n",
    "    \n",
    "    # Iterate over each property of the current year\n",
    "    for idx, current_property in current_year_properties.iterrows():\n",
    "        # Subtract geometries of older properties from the current property\n",
    "        for _, older_property in final_properties.iterrows():\n",
    "            current_property['geometry'] = current_property['geometry'].difference(older_property['geometry'])\n",
    "        \n",
    "        # Append the \"cut\" current property to the final_properties GeoDataFrame\n",
    "        final_properties = pd.concat([final_properties, current_property.to_frame().T])\n",
    "final_properties.crs = properties.crs'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_path = os.path.join(DATA_PATH,\\'preprocessing\\' \"dataset-clip\")\\n\\n# Convert the \\'fecha_res\\' column to a string format\\nfinal_properties[\\'fecha_res\\'] = final_properties[\\'fecha_res\\'].astype(str)\\n\\n# Create the directory if it doesn\\'t exist\\nif not os.path.exists(output_path):\\n    os.makedirs(output_path)\\n    # Save the GeoDataFrame as a GeoPackage\\n# Define the filename for the GeoPackage\\n\\nfilename = os.path.join(output_path, \"datset-clip.gpkg\")\\nfinal_properties.to_file(filename, driver=\"GPKG\")'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''output_path = os.path.join(DATA_PATH,'preprocessing' \"dataset-clip\")\n",
    "\n",
    "# Convert the 'fecha_res' column to a string format\n",
    "final_properties['fecha_res'] = final_properties['fecha_res'].astype(str)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    # Save the GeoDataFrame as a GeoPackage\n",
    "# Define the filename for the GeoPackage\n",
    "\n",
    "filename = os.path.join(output_path, \"datset-clip.gpkg\")\n",
    "final_properties.to_file(filename, driver=\"GPKG\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_path = os.path.join(DATA_PATH, \"limit-subsets\")\\n# Create the directory if it doesn\\'t exist\\nif not os.path.exists(output_path):\\n    os.makedirs(output_path)\\n\\nfor year in sorted(filtered_limit[\\'anho_capa\\'].unique()):\\n    year_gdf = filtered_limit[filtered_limit[\\'anho_capa\\'] == year]\\n    \\n    # Define the filename for the GeoPackage\\n    filename = os.path.join(output_path, f\"year_{year}.gpkg\")\\n    \\n    # Save the GeoDataFrame as a GeoPackage\\n    year_gdf.to_file(filename, driver=\"GPKG\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''output_path = os.path.join(DATA_PATH, \"limit-subsets\")\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for year in sorted(filtered_limit['anho_capa'].unique()):\n",
    "    year_gdf = filtered_limit[filtered_limit['anho_capa'] == year]\n",
    "    \n",
    "    # Define the filename for the GeoPackage\n",
    "    filename = os.path.join(output_path, f\"year_{year}.gpkg\")\n",
    "    \n",
    "    # Save the GeoDataFrame as a GeoPackage\n",
    "    year_gdf.to_file(filename, driver=\"GPKG\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create a list of GeoDataFrames for each year\\nyear_gdfs = [gpd.read_file(os.path.join(LIMIT_SUBSETS[0], year_file))             for year_file in sorted(os.listdir(LIMIT_SUBSETS[0])) if year_file.endswith('.gpkg')]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Create a list of GeoDataFrames for each year\n",
    "year_gdfs = [gpd.read_file(os.path.join(LIMIT_SUBSETS[0], year_file))\\\n",
    "             for year_file in sorted(os.listdir(LIMIT_SUBSETS[0])) if year_file.endswith('.gpkg')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile using geopandas\n",
    "limit_subset = gpd.read_file(LIMIT_SUBSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>put_id</th>\n",
       "      <th>anho_capa</th>\n",
       "      <th>fecha_res</th>\n",
       "      <th>area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176</td>\n",
       "      <td>PUT0176</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-19 00:00:00</td>\n",
       "      <td>5936099.973155426</td>\n",
       "      <td>MULTIPOLYGON (((284617.950 7557184.826, 284608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>511</td>\n",
       "      <td>PUT0511</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-02-01 00:00:00</td>\n",
       "      <td>5951123.782286445</td>\n",
       "      <td>MULTIPOLYGON (((155454.161 7586494.623, 157619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>467</td>\n",
       "      <td>PUT0467</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-02-10 00:00:00</td>\n",
       "      <td>47778603.62791812</td>\n",
       "      <td>MULTIPOLYGON (((417515.525 7395323.775, 417870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>PUT0512</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-03-07 00:00:00</td>\n",
       "      <td>3835414.179348219</td>\n",
       "      <td>MULTIPOLYGON (((152259.745 7546016.649, 152183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>PUT0169</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-03-07 00:00:00</td>\n",
       "      <td>10635728.4837288</td>\n",
       "      <td>MULTIPOLYGON (((195978.190 7538496.754, 193320...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>3261</td>\n",
       "      <td>PUT3261</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>90443701</td>\n",
       "      <td>MULTIPOLYGON (((-23420.518 7565678.215, -21240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>3390</td>\n",
       "      <td>PUT3390</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>90507689</td>\n",
       "      <td>MULTIPOLYGON (((318174.855 7815778.151, 318136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>3568</td>\n",
       "      <td>PUT3568</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>45633418</td>\n",
       "      <td>MULTIPOLYGON (((52460.448 7501322.034, 52460.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>3572</td>\n",
       "      <td>PUT3572</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>107722489</td>\n",
       "      <td>MULTIPOLYGON (((123862.160 7596438.754, 123875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>3577</td>\n",
       "      <td>PUT3577</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>4608139</td>\n",
       "      <td>MULTIPOLYGON (((-30711.083 7612498.623, -32012...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   put_id anho_capa            fecha_res               area  \\\n",
       "0      176  PUT0176      2000  2000-01-19 00:00:00  5936099.973155426   \n",
       "1      511  PUT0511      2000  2000-02-01 00:00:00  5951123.782286445   \n",
       "2      467  PUT0467      2000  2000-02-10 00:00:00  47778603.62791812   \n",
       "3      512  PUT0512      2000  2000-03-07 00:00:00  3835414.179348219   \n",
       "4      169  PUT0169      2000  2000-03-07 00:00:00   10635728.4837288   \n",
       "...    ...      ...       ...                  ...                ...   \n",
       "3209  3261  PUT3261      2018           2018-02-01           90443701   \n",
       "3210  3390  PUT3390      2020           2020-10-28           90507689   \n",
       "3211  3568  PUT3568      2022           2022-01-13           45633418   \n",
       "3212  3572  PUT3572      2021           2021-02-24          107722489   \n",
       "3213  3577  PUT3577      2021           2021-04-05            4608139   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((284617.950 7557184.826, 284608...  \n",
       "1     MULTIPOLYGON (((155454.161 7586494.623, 157619...  \n",
       "2     MULTIPOLYGON (((417515.525 7395323.775, 417870...  \n",
       "3     MULTIPOLYGON (((152259.745 7546016.649, 152183...  \n",
       "4     MULTIPOLYGON (((195978.190 7538496.754, 193320...  \n",
       "...                                                 ...  \n",
       "3209  MULTIPOLYGON (((-23420.518 7565678.215, -21240...  \n",
       "3210  MULTIPOLYGON (((318174.855 7815778.151, 318136...  \n",
       "3211  MULTIPOLYGON (((52460.448 7501322.034, 52460.4...  \n",
       "3212  MULTIPOLYGON (((123862.160 7596438.754, 123875...  \n",
       "3213  MULTIPOLYGON (((-30711.083 7612498.623, -32012...  \n",
       "\n",
       "[3214 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy",
   "language": "python",
   "name": "policy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
